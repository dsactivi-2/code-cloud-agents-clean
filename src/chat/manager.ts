/**
 * Chat Manager - Orchestrates chat sessions with agents
 */

import { ChatStorage } from "./storage.ts";
import type {
  ChatRequest,
  ChatResponse,
  ChatMessage,
  Chat,
} from "./types.ts";
import { costTracker } from "../billing/costTracker.ts";
import { selectModel } from "../billing/modelSelector.ts";
import Anthropic from "@anthropic-ai/sdk";
import OpenAI from "openai";
import { GoogleGenerativeAI } from "@google/generative-ai";

export class ChatManager {
  private storage: ChatStorage;

  constructor(storage: ChatStorage) {
    this.storage = storage;
  }

  /**
   * Send message to agent and get response
   */
  async sendMessage(request: ChatRequest): Promise<ChatResponse> {
    // Get or create chat
    let chat: Chat;
    if (request.chatId) {
      chat = this.storage.getChat(request.chatId)!;
      if (!chat) {
        throw new Error(`Chat ${request.chatId} not found`);
      }
    } else {
      // Create new chat with auto-generated title
      const title = this.generateTitle(request.message);
      chat = this.storage.createChat(
        request.userId,
        title,
        request.agentName
      );
    }

    // Store user message
    this.storage.addMessage({
      chatId: chat.id,
      role: "user",
      content: request.message,
    });

    // Get chat history for context (if requested)
    const history: ChatMessage[] = request.includeHistory
      ? this.storage.getRecentMessages(
          chat.id,
          request.maxHistory || 10
        )
      : [];

    // Build prompt with history
    const prompt = this.buildPrompt(request.message, history, request.agentName);

    // Select optimal model
    const modelRecommendation = selectModel(request.message, {
      preferLocal: false,
    });

    const modelToUse = request.model || modelRecommendation.model;
    const providerToUse = request.modelProvider || modelRecommendation.provider;

    // Call AI provider
    const aiResponse = await this.callAIProvider(
      providerToUse,
      modelToUse,
      prompt,
      request.agentName
    );

    // Store assistant response
    const assistantMessage = this.storage.addMessage({
      chatId: chat.id,
      role: "assistant",
      content: aiResponse.content,
      agentName: request.agentName,
      tokens: aiResponse.tokens,
    });

    // Track costs
    if (aiResponse.tokens) {
      costTracker.log({
        userId: request.userId,
        taskId: chat.id,
        model: modelToUse,
        provider: providerToUse,
        inputTokens: aiResponse.tokens.input,
        outputTokens: aiResponse.tokens.output,
      });
    }

    return {
      chatId: chat.id,
      messageId: assistantMessage.id,
      agentName: request.agentName,
      content: aiResponse.content,
      timestamp: assistantMessage.timestamp,
      tokens: aiResponse.tokens,
      cost: aiResponse.cost,
    };
  }

  /**
   * Get chat history
   */
  getChatHistory(chatId: string, limit = 50, offset = 0) {
    const messages = this.storage.getMessages(chatId, limit, offset);
    const total = this.storage.countMessages(chatId);

    return {
      chatId,
      messages,
      total,
      hasMore: offset + messages.length < total,
    };
  }

  /**
   * List user's chats
   */
  listChats(userId: string, page = 1, pageSize = 20) {
    const offset = (page - 1) * pageSize;
    const chats = this.storage.listChats(userId, pageSize, offset);
    const total = this.storage.countChats(userId);

    return {
      chats: chats.map((chat) => ({
        chatId: chat.id,
        title: chat.title,
        agentName: chat.agentName,
        messageCount: chat.messageCount,
        lastMessage: chat.lastMessage || "",
        createdAt: chat.createdAt,
        updatedAt: chat.updatedAt,
      })),
      total,
      page,
      pageSize,
    };
  }

  /**
   * Delete chat
   */
  deleteChat(chatId: string): void {
    this.storage.deleteChat(chatId);
  }

  /**
   * Update chat title
   */
  updateChatTitle(chatId: string, title: string): void {
    this.storage.updateChatTitle(chatId, title);
  }

  /**
   * Generate chat title from first message
   */
  private generateTitle(message: string): string {
    // Take first 50 chars or first sentence
    const shortened = message.substring(0, 50);
    return shortened.length < message.length
      ? shortened + "..."
      : shortened;
  }

  /**
   * Build prompt with chat history
   */
  private buildPrompt(
    message: string,
    history: ChatMessage[],
    agentName: string
  ): string {
    let prompt = "";

    // Add system message for agent
    prompt += `You are ${agentName}, a helpful AI assistant.\n\n`;

    // Add chat history
    if (history.length > 0) {
      prompt += "Previous conversation:\n";
      for (const msg of history) {
        if (msg.role === "user") {
          prompt += `User: ${msg.content}\n`;
        } else if (msg.role === "assistant") {
          prompt += `${msg.agentName || "Assistant"}: ${msg.content}\n`;
        }
      }
      prompt += "\n";
    }

    // Add current message
    prompt += `User: ${message}\n`;
    prompt += `${agentName}: `;

    return prompt;
  }

  /**
   * Call AI provider with actual API integration
   */
  private async callAIProvider(
    provider: string,
    model: string,
    prompt: string,
    agentName: string
  ): Promise<{
    content: string;
    tokens?: { input: number; output: number; total: number };
    cost?: { usd: number; eur: number };
  }> {
    console.log(`[Chat] Calling ${provider}/${model} for agent ${agentName}`);

    try {
      switch (provider.toLowerCase()) {
        case "anthropic":
          return await this.callAnthropic(model, prompt, agentName);
        case "openai":
          return await this.callOpenAI(model, prompt, agentName);
        case "gemini":
          return await this.callGemini(model, prompt, agentName);
        default:
          throw new Error(`Unsupported provider: ${provider}`);
      }
    } catch (error: any) {
      console.error(`[Chat] Error calling ${provider}:`, error);
      throw new Error(
        `Failed to call ${provider}: ${error.message || "Unknown error"}`
      );
    }
  }

  /**
   * Call Anthropic Claude API
   */
  private async callAnthropic(
    model: string,
    prompt: string,
    agentName: string
  ): Promise<{
    content: string;
    tokens: { input: number; output: number; total: number };
    cost: { usd: number; eur: number };
  }> {
    const apiKey = process.env.ANTHROPIC_API_KEY;
    if (!apiKey) {
      throw new Error("ANTHROPIC_API_KEY not configured");
    }

    const client = new Anthropic({ apiKey });

    const response = await client.messages.create({
      model: model || "claude-3-5-sonnet-20241022",
      max_tokens: 4096,
      messages: [
        {
          role: "user",
          content: prompt,
        },
      ],
      system: `You are ${agentName}, a helpful AI assistant.`,
    });

    const content =
      response.content[0].type === "text" ? response.content[0].text : "";

    const inputTokens = response.usage.input_tokens;
    const outputTokens = response.usage.output_tokens;

    // Cost calculation (Claude 3.5 Sonnet pricing: $3/MTok input, $15/MTok output)
    const inputCostUSD = (inputTokens / 1_000_000) * 3;
    const outputCostUSD = (outputTokens / 1_000_000) * 15;
    const totalCostUSD = inputCostUSD + outputCostUSD;

    return {
      content,
      tokens: {
        input: inputTokens,
        output: outputTokens,
        total: inputTokens + outputTokens,
      },
      cost: {
        usd: totalCostUSD,
        eur: totalCostUSD * 0.92, // Approximate EUR conversion
      },
    };
  }

  /**
   * Call OpenAI GPT API
   */
  private async callOpenAI(
    model: string,
    prompt: string,
    agentName: string
  ): Promise<{
    content: string;
    tokens: { input: number; output: number; total: number };
    cost: { usd: number; eur: number };
  }> {
    const apiKey = process.env.OPENAI_API_KEY;
    if (!apiKey) {
      throw new Error("OPENAI_API_KEY not configured");
    }

    const client = new OpenAI({ apiKey });

    const response = await client.chat.completions.create({
      model: model || "gpt-4",
      messages: [
        {
          role: "system",
          content: `You are ${agentName}, a helpful AI assistant.`,
        },
        {
          role: "user",
          content: prompt,
        },
      ],
      max_tokens: 4096,
    });

    const content = response.choices[0].message.content || "";
    const inputTokens = response.usage?.prompt_tokens || 0;
    const outputTokens = response.usage?.completion_tokens || 0;

    // Cost calculation (GPT-4 pricing: $30/MTok input, $60/MTok output)
    const inputCostUSD = (inputTokens / 1_000_000) * 30;
    const outputCostUSD = (outputTokens / 1_000_000) * 60;
    const totalCostUSD = inputCostUSD + outputCostUSD;

    return {
      content,
      tokens: {
        input: inputTokens,
        output: outputTokens,
        total: inputTokens + outputTokens,
      },
      cost: {
        usd: totalCostUSD,
        eur: totalCostUSD * 0.92,
      },
    };
  }

  /**
   * Call Google Gemini API
   */
  private async callGemini(
    model: string,
    prompt: string,
    agentName: string
  ): Promise<{
    content: string;
    tokens: { input: number; output: number; total: number };
    cost: { usd: number; eur: number };
  }> {
    const apiKey = process.env.GEMINI_API_KEY;
    if (!apiKey) {
      throw new Error("GEMINI_API_KEY not configured");
    }

    const genAI = new GoogleGenerativeAI(apiKey);
    const geminiModel = genAI.getGenerativeModel({
      model: model || "gemini-pro",
    });

    const systemInstruction = `You are ${agentName}, a helpful AI assistant.`;
    const fullPrompt = `${systemInstruction}\n\n${prompt}`;

    const result = await geminiModel.generateContent(fullPrompt);
    const response = result.response;
    const content = response.text();

    // Gemini doesn't provide detailed token usage, estimate it
    const inputTokens = Math.floor(fullPrompt.length / 4);
    const outputTokens = Math.floor(content.length / 4);

    // Cost calculation (Gemini pricing: $0.5/MTok input, $1.5/MTok output)
    const inputCostUSD = (inputTokens / 1_000_000) * 0.5;
    const outputCostUSD = (outputTokens / 1_000_000) * 1.5;
    const totalCostUSD = inputCostUSD + outputCostUSD;

    return {
      content,
      tokens: {
        input: inputTokens,
        output: outputTokens,
        total: inputTokens + outputTokens,
      },
      cost: {
        usd: totalCostUSD,
        eur: totalCostUSD * 0.92,
      },
    };
  }
}
